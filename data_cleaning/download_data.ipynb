{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "#Data accessible via: \n",
    "git clone https://huggingface.co/datasets/liminghao1630/API-Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os \n",
    "DATA_ROOT = 'API-Bank' \n",
    "OUTPUT_PATH = '../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.join(DATA_ROOT,'test-data/level-3.json')\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "RANDOM_STATE = 42\n",
    "            \n",
    "\n",
    "def load_jsons_from_dir(test_data_path):\n",
    "    \"\"\"Get the JSONs from a given directory, load them into a DF and return a list of DFs\"\"\"\n",
    "    test_files = os.listdir(test_data_path)\n",
    "    dfs = []\n",
    "    for file in test_files:\n",
    "        fp = os.path.join(test_data_path,file)\n",
    "        df = pd.read_json(fp)\n",
    "        # dfs.append(df)\n",
    "        if \"expected_output\" in df.columns:\n",
    "            df = df.rename({'expected_output':'output'},axis=1)\n",
    "            print(df.columns)\n",
    "\n",
    "        df_cols=df.columns \n",
    "        # drop any column which is not 'input','output', or 'instruction'\n",
    "        keep_cols =['input','output', 'instruction']\n",
    "\n",
    "        for col in df_cols:\n",
    "            if not (col in keep_cols):\n",
    "                df=df.drop(columns=col)\n",
    "                print(f\"dropped {col}\")\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concat all the test dfs\n",
    "test_dfs = load_jsons_from_dir(os.path.join(DATA_ROOT,'test-data'))\n",
    "test_df = pd.concat(test_dfs)\n",
    "test_df['split'] = 'test'\n",
    "\n",
    "# Concat all the train DFs\n",
    "train_dfs = load_jsons_from_dir(os.path.join(DATA_ROOT,'training-data'))\n",
    "train_df = pd.concat(train_dfs)\n",
    "train_df['split'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Concat test and train DFs into a single DF\n",
    "api_df = pd.concat([train_df,test_df],axis=0).reset_index(drop=True)\n",
    "api_df = api_df.drop_duplicates()\n",
    "api_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Identify API request versus API response rows\n",
    "api_df['query_type'] = api_df['output'].apply(lambda x: 'API_request' if str(x).startswith('API-Request') else 'AI' if str(x).startswith('AI') else 'Other')\n",
    "api_df.groupby(['query_type','split']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(api_df.shape[0])\n",
    "# Keep only the API requests (see report for reasoning)\n",
    "api_df = api_df[api_df['query_type']=='API_request']\n",
    "print(api_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# TIdy\n",
    "api_df['cleaned_output'] = api_df['output'].str.replace(\"API-Request:\",\"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Get the instruction queries\n",
    "api_df['instruction_query_type'] = api_df['instruction'].apply(lambda x: x.split('\\n')[1])\n",
    "api_df.groupby(['instruction_query_type','split']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_func_calls(input_string):\n",
    "    \"\"\"Pull out the function calls\"\"\"\n",
    "    pattern = r'\\b\\w+\\([^()]*\\)'\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Get all the functions out\n",
    "api_df['function_calls'] = api_df['cleaned_output'].apply(parse_func_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Despite what the API Bank paper says, only one function call is used at a tie\n",
    "api_df['number_of_calls'] = api_df['function_calls'].apply(len)\n",
    "api_df['number_of_calls'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Since there is only one function call at a time, just keep that one\n",
    "api_df['function_call'] = api_df['function_calls'].apply(lambda x: x[0] if len(x)>0 else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Pull out the function name -- used in later eval metrics\n",
    "api_df['function_name'] = api_df['function_call'].apply(lambda x: x.split(\"(\")[0] if (\"(\" in x) else \"None\")\n",
    "plt.xlim((0,50))\n",
    "api_df.groupby('function_name').count()['function_call'].sort_values(ascending=False).plot(kind='hist',bins=2000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Concat instruction and inputs into a single prompt\n",
    "api_df['prompt'] = api_df['instruction'] + \"\\n\"+ api_df['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# How many in each?\n",
    "api_df.groupby('split').count()\n",
    "\n",
    "api_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Rename cleaned_output to completion\n",
    "api_df = api_df.rename({'cleaned_output':'completion'},axis=1)\n",
    "api_df['split'] = api_df['split'].apply(lambda x: 'eval' if x == 'train' and random.random() < 0.1 else x)\n",
    "api_df.groupby('split').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# output\n",
    "api_df.to_csv(os.path.join(OUTPUT_PATH,'cleaned_api_bank_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# delete the old folder\n",
    "import shutil \n",
    "shutil.rmtree('API-Bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
