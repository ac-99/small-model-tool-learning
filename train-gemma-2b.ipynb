{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m load_dotenv()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      6\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      7\u001b[0m LR\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2e-4\u001b[39m,\n",
      "File \u001b[0;32m~/miniconda3/envs/tool-learning/lib/python3.11/site-packages/wandb/__init__.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# This needs to be early as other modules call it.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mterm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m termsetup, termlog, termerror, termwarn\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdk \u001b[38;5;28;01mas\u001b[39;00m wandb_sdk\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     31\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwandb_lib \u001b[38;5;241m=\u001b[39m wandb_sdk\u001b[38;5;241m.\u001b[39mlib  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tool-learning/lib/python3.11/site-packages/wandb/sdk/__init__.py:25\u001b[0m\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSettings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_helper \u001b[38;5;28;01mas\u001b[39;00m helper\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifacts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artifact\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_alerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertLevel\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n",
      "File \u001b[0;32m~/miniconda3/envs/tool-learning/lib/python3.11/site-packages/wandb/sdk/artifacts/artifact.py:72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Api \u001b[38;5;28;01mas\u001b[39;00m InternalApi\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthread_local_settings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _thread_local_api_settings\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filesystem, retry, runid, telemetry\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m B64MD5, b64_to_hex_id, md5_file_b64\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmailbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mailbox\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import wandb\n",
    "\n",
    "\n",
    "R = 8\n",
    "LR= 2e-4,\n",
    "EPOCHS=10\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"tool-learning\",\n",
    "    name=\"sample\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"r\": R,\n",
    "    \"dataset\": \"api_bank\",\n",
    "    \"epochs\": EPOCHS,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL = \"microsoft/phi-2\"# \"microsoft/phi-2\"\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     # load_in_4bit=True,\n",
    "#     # bnb_4bit_quant_type=\"nf4\",\n",
    "#     # bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "tokeniser = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, \n",
    "                                                #  attn_implementation=\"flash_attention_2\",\n",
    "                                                #  quantization_config = ...\n",
    "                                             )#quantization_config=bnb_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=R,\n",
    "    # target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate an API request in the format of [ApiName(key1='value1', key2='value2', ...)] based on the previous dialogue context.\n",
      "The current time is 2039-03-09 18:56:09 Wednesday.\n",
      "Input: \n",
      "User: User's utterence\n",
      "AI: AI's response\n",
      "\n",
      "Expected output:\n",
      "API-Request: [ApiName(key1='value1', key2='value2', ...)]\n",
      "\n",
      "API descriptions:\n",
      "\n",
      "{\"apiCode\": \"Get_All_Sessions\", \"description\": \"Get the list of all available yoga and meditation sessions.\", \"parameters\": {}, \"response\": {\"data\": {\"description\": \"List of available sessions.\", \"type\": \"list\", \"items\": {\"type\": \"object\", \"properties\": {\"session_name\": {\"description\": \"Name of the session.\", \"type\": \"string\"}, \"session_date\": {\"description\": \"Date of the session.\", \"type\": \"string\", \"format\": \"formatted\"}, \"session_time\": {\"description\": \"Time of the session.\", \"type\": \"string\", \"format\": \"formatted\"}, \"session_instructor\": {\"description\": \"Name of the session instructor.\", \"type\": \"string\"}, \"session_description\": {\"description\": \"Description of the session.\", \"type\": \"string\"}}}}}}\n",
      "{\"apiCode\": \"Create_New_Session\", \"description\": \"Create a new virtual yoga or meditation session.\", \"parameters\": {\"session_name\": {\"type\": \"string\", \"description\": \"Name of the session.\", \"required\": true}, \"session_date\": {\"type\": \"string\", \"description\": \"Date of the session, in the format yyyy-MM-dd.\", \"format\": \"formatted\", \"required\": true}, \"session_time\": {\"type\": \"string\", \"description\": \"Time of the session, in the format HH:mm:ss.\", \"format\": \"formatted\", \"required\": true}, \"session_instructor\": {\"type\": \"string\", \"description\": \"Name of the session instructor.\", \"required\": true}, \"session_description\": {\"type\": \"string\", \"description\": \"Description of the session.\", \"required\": true}}, \"response\": {\"data\": {\"description\": \"Confirmation of new session creation.\", \"type\": \"object\", \"properties\": {\"session_id\": {\"type\": \"integer\", \"description\": \"ID of the newly created session.\"}, \"status\": {\"type\": \"string\", \"description\": \"Status of the creation request.\"}}}}}\n",
      "{\"apiCode\": \"Register_for_Session\", \"description\": \"Register for a virtual yoga or meditation session.\", \"parameters\": {\"session_id\": {\"type\": \"integer\", \"description\": \"ID of the session to register for.\", \"required\": true}, \"user_name\": {\"type\": \"string\", \"description\": \"Name of the user registering for the session.\", \"required\": true}, \"user_email\": {\"type\": \"string\", \"description\": \"Email of the user registering for the session.\", \"required\": true}, \"user_phone\": {\"type\": \"string\", \"description\": \"Phone number of the user registering for the session.\", \"required\": true}}, \"response\": {\"data\": {\"description\": \"Confirmation of session registration.\", \"type\": \"object\", \"properties\": {\"session_name\": {\"type\": \"string\", \"description\": \"Name of the session the user registered for.\"}, \"user_name\": {\"type\": \"string\", \"description\": \"Name of the user who registered for the session.\"}, \"status\": {\"type\": \"string\", \"description\": \"Status of the registration request.\"}}}}}\n",
      "User: I'm interested in joining a virtual yoga or meditation session. Can you provide me with a list of all available sessions?\n",
      "Generate API Request: \n",
      "[Get_All_Sessions()]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "api_bank_df = pd.read_csv('Datasets/API-Bank/cleaned_api_bank_data.csv')\n",
    "\n",
    "print(api_bank_df.prompt.iloc[0])\n",
    "print(api_bank_df.completion.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'instruction', 'input', 'output', 'split', 'query_type', 'completion', 'instruction_query_type', 'function_calls', 'number_of_calls', 'function_call', 'function_name', 'prompt', '__index_level_0__'],\n",
      "    num_rows: 9321\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'instruction', 'input', 'output', 'split', 'query_type', 'completion', 'instruction_query_type', 'function_calls', 'number_of_calls', 'function_call', 'function_name', 'prompt', '__index_level_0__'],\n",
      "    num_rows: 997\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'instruction', 'input', 'output', 'split', 'query_type', 'completion', 'instruction_query_type', 'function_calls', 'number_of_calls', 'function_call', 'function_name', 'prompt', '__index_level_0__'],\n",
      "    num_rows: 1047\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "api_train = Dataset.from_pandas(api_bank_df[api_bank_df['split']=='train'])\n",
    "api_test = Dataset.from_pandas(api_bank_df[api_bank_df['split']=='test'])\n",
    "api_eval = Dataset.from_pandas(api_bank_df[api_bank_df['split']=='eval'])\n",
    "\n",
    "for dataset in [api_train, api_test, api_eval]:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/trl/en/sft_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[Amax_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<trl.trainer.sft_trainer.SFTTrainer at 0x7c5a4e4ae190>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "            per_device_train_batch_size=1,\n",
    "            gradient_accumulation_steps=4,\n",
    "            warmup_steps=2,\n",
    "            max_snumteps=EPOCHS,\n",
    "            learning_rate=LR,\n",
    "            fp16=False,\n",
    "            logging_steps=1,\n",
    "            output_dir=\"outputs\",\n",
    "            optim=\"paged_adamw_8bit\",\n",
    "            report_to=\"wandb\",\n",
    "        )\n",
    "\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['question'])):\n",
    "        text = f\"### Prompt: {example['prompt'][i]}\\n ### Completion: {example['completion'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=api_train,\n",
    "    eval_dataset=api_eval,\n",
    "        args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    # data_collator=data_collator\n",
    "    formatting_func = formatting_prompts_func\n",
    ")\n",
    "# trainer.train()\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
